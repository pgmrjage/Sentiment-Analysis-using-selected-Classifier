setwd("D:\\School Workspace\\Source Codes\\R Language\\Classifier")
df <- read.csv("imdb.csv")
df_1000 <- df[1:1000, ]
View(df_1000)
training_set <- df_1000[1:800]
training_set <- df_1000[1:800, ]
View(training_set)
View(training_set)
testing_set <- df_1000[800:1000, ]
View(training_set)
View(training_set)
View(testing_set)
testing_set_count <- table(as.factor(training_set))
testing_set_count <- table(training_set)
testing_set_count
View(training_set)
View(testing_set_count)
testing_set_count <- as.factor(training_set)
testing_set_count <- as.factor(testing_set$sentiment)
View(testing_set_count)
print(testing_set_count)
testing_set_count <- table(as.factor(testing_set$sentiment))
print(testing_set_count)
len(training_set)
len(testing_set_count)
len(testing_set)
training_set_count <- table(as.factor(training_set$sentiment))
print(training_set_count)
summary(training_set_count)
plot(training_set_count, testing_set_count)
plot(training_set_count)
plot(training_set_count, training_set)
lm_model <- lm(testing_set ~ training_set, data = training_set)
# Assuming 'feature1' is your independent variable and 'sentiment' is your dependent variable
# If these columns are not numeric, you'll need to preprocess them.
# Fit the linear regression model
lm_model <- lm(sentiment ~ feature1, data = training_set)
relation <- lm (training_set ~ training_set_count)
relation <- lm (training_set_count ~ as.factor(training_set$sentiment))
relation <- lm (training_set_count ~ table(as.factor(training_set$sentiment)))
summary(relation)
plot(relation)
str(df_1000)
df_1000$sentiment <- factor(df_1000$sentiment, levels = c("negative", "neutral", "positive"))
df_1000 <- df[1:1000, ]
df_1000$sentiment <- factor(df_1000$sentiment, levels = c("negative", "neutral", "positive"))
training_set <- df_1000[1:800, ]
testing_set <- df_1000[800:1000, ]
str(df_1000)
View(df_1000)
# Train a Naive Bayes classifier using the training data
nb_model <- naiveBayes(train_dtm, training_set$sentiment)
install.packages(naivebayes)
install.packages("naivebayes")
library(naivebayes)
nb_model <- naiveBayes(train_dtm, training_set$sentiment)
nb_model <- naiveBayes(training_set, training_set$sentiment)
nb_model <- naivebayes(training_set, training_set$sentiment)
nb_model <- naive_bayes(training_set, training_set$sentiment)
View(nb_model)
View(nb_model)
nb_predictions <- predict(nb_model, test_dtm)
nb_model <- naive_bayes(df_1000, training_set$sentiment)
nb_model <- naive_bayes(training_set, training_set$sentiment)
# Predict on the testing set
nb_predictions <- predict(nb_model, testing_set)
# Train a Naive Bayes classifier using the training data
nb_model <- naive_bayes(training_set, training_set$sentiment)
# Predict on the testing set
nb_predictions <- predict(nb_model, testing_set$sentiment)
# Train a Naive Bayes classifier using the training data
nb_model <- naive_bayes(df_1000, training_set$sentiment)
View(df_1000)
View(relation)
View(nb_model)
df <- read.csv("train_df.csv")
df_1000 <- (1:1000, )
df_1000 <-df[1:1000, ]
train_data <- df_1000[1:800, ]
test_data <- df_1000[800:1000, ]
View(test_data)
str(df_1000)
mod <- lm(train_data$id ~ table(as.factor(train_data$sentiment)))
sentiment_count <- table(as.factor(train_data$sentiment))
summary(sentiment_count)
print(sentiment_count)
mod <- lm(train_data$id ~ sentiment_count)
mod <- lm(train_data$id ~ train_data$sentiment)
summary(mod)
plot(mod)
mod <- lm(train_data$sentiment ~ train_data$id)
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
mod <- lm(train_data$sentiment ~ train_data$id)
summary(mod)
summary(mod)
plot(mod)
mod <- lm(train_data$sentiment ~ train_data$label)
mod <- lm(train_data$sentiment ~ train_data$label)
mod <- lm(train_data$sentiment ~ train_data$id)
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
plot(train_data$id, train_data$sentiment, main="Linear Regression", xlab="ID", ylab="Sentiment")
str(df_1000)
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
plot(train_data$id, train_data$sentiment, main="Linear Regression", xlab="ID", ylab="Sentiment")
setwd("D:\\School Workspace\\Source Codes\\R Language\\Classifier")
df <- read.csv("train_df.csv")
df_1000 <-df[1:1000, ]
train_data <- df_1000[1:800, ]
test_data <- df_1000[800:1000, ]
str(df_1000)
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
mod <- lm(train_data$sentiment ~ id, data=train_data)
mod <- lm(train_data$sentiment ~ id, data=train_data)
mod <- lm(train_data$sentiment ~ train_data$id)
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
mod <- lm(train_data$id ~ train_data$sentiment)
summary(mod)
plot(mod)
setwd("D:\\School Workspace\\Source Codes\\R Language\\Classifier")
df <- read.csv("train_df.csv")
str(df)
df$sentiment <- factor(df$sentiment, levels = c("negative", "neutral", "positive"))
df_1000 <- df[1:1000, ]  # Select first 1000 rows
train_data <- df_1000[1:800, ]
test_data <- df_1000[801:1000,
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
mod <- lm(label ~ sentiment, data = train_data)
summary(mod)
plot(mod)
train_data$sentiment_numeric <- as.numeric(train_data$sentiment)
plot(train_data$sentiment_numeric, train_data$label,
xlab = "Sentiment", ylab = "Label",
main = "Linear Regression: Sentiment vs Label",
pch = 19, col = "blue")
abline(mod, col = "red", lwd = 2)  # This adds the regression line
# Alternatively, using ggplot2 for a more advanced plot
library(ggplot2)
ggplot(train_data, aes(x = sentiment_numeric, y = label)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Linear Regression: Sentiment vs Label", x = "Sentiment", y = "Label")
plot(train_data$sentiment_numeric, train_data$label,
xlab = "Sentiment", ylab = "Label",
main = "Linear Regression: Sentiment vs Label",
pch = 19, col = "blue")
train_data$sentiment_numeric <- as.numeric(train_data$sentiment)
# Plot label vs sentiment
plot(train_data$sentiment_numeric, train_data$label,
xlab = "Sentiment", ylab = "Label",
main = "Linear Regression: Sentiment vs Label",
pch = 19, col = "blue")
# Add the regression line
abline(mod, col = "red", lwd = 2)  # This adds the regression line
# Alternatively, using ggplot2 for a more advanced plot
library(ggplot2)
ggplot(train_data, aes(x = sentiment_numeric, y = label)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Linear Regression: Sentiment vs Label", x = "Sentiment", y = "Label")
plot(mod)
# Set working directory and load the dataset
setwd("D:\\School Workspace\\Source Codes\\R Language\\Classifier")
df <- read.csv("train_df.csv")
# Inspect the structure of the data
str(df)
# Convert 'sentiment' to a factor variable (since it's categorical)
df$sentiment <- factor(df$sentiment, levels = c("negative", "neutral", "positive"))
# Split data into training and testing datasets
df_1000 <- df[1:1000, ]  # Select first 1000 rows
train_data <- df_1000[1:800, ]
test_data <- df_1000[801:1000, ]
# Summary of 'sentiment' count in the training data
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
# Let's say we want to predict the 'label' column based on the 'sentiment' column
# Train a linear regression model
mod <- lm(label ~ sentiment, data = train_data)
# View summary of the linear model
summary(mod)
# Plot the linear regression model (diagnostic plots)
plot(mod)
# Convert 'sentiment' to a numeric factor for plotting
train_data$sentiment_numeric <- as.numeric(train_data$sentiment)
# Plot label vs sentiment
plot(train_data$sentiment_numeric, train_data$label,
xlab = "Sentiment", ylab = "Label",
main = "Linear Regression: Sentiment vs Label",
pch = 19, col = "blue")
# Add the regression line
abline(mod, col = "red", lwd = 2)  # This adds the regression line
# Alternatively, using ggplot2 for a more advanced plot
library(ggplot2)
ggplot(train_data, aes(x = sentiment_numeric, y = label)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Linear Regression: Sentiment vs Label", x = "Sentiment", y = "Label")
View(train_data)
View(train_data)
df <- read.csv("train_df.csv")
# Data Preprocessing
# Convert text to lower case
corpus <- Corpus(VectorSource(df$text))
install.packages(c("tm", "caret", "kernlab", "randomForest", "e1071", "ggplot2", "dplyr"))
library(tm)
library(caret)
library(kernlab)
library(randomForest)
library(e1071)
library(ggplot2)
library(dplyr)
df <- read.csv("train_df.csv")
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stripWhitespace)
# Create a Document-Term Matrix (DTM) and apply TF-IDF
dtm <- DocumentTermMatrix(corpus)
tfidf <- weightTfIdf(dtm)
# Convert DTM to a data frame
tfidf_df <- as.data.frame(as.matrix(tfidf))
install.packages(c("tm", "caret", "kernlab", "randomForest", "e1071", "ggplot2", "dplyr"))
library(tm)          # Text mining
library(caret)       # Machine learning and evaluation
library(kernlab)     # Support Vector Machine (SVM)
library(randomForest) # Random Forest
library(e1071)        # For Naive Bayes and SVM
library(ggplot2)      # Plotting
library(dplyr)        # Data manipulation
df <- read.csv("train_df.csv")
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(tolower))       # Convert to lower case
corpus <- tm_map(corpus, removePunctuation)                   # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                       # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))        # Remove stopwords
corpus <- tm_map(corpus, stripWhitespace)                     # Remove extra spaces
tm <- DocumentTermMatrix(corpus)
tfidf <- weightTfIdf(dtm)  # Apply TF-IDF transformation
df <- read.csv("train_df.csv")
install.packages(caret)
library(caret)
set.seed(42)
train_index <- createDataPartition(df$label, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
# Set working directory and load the dataset
setwd("D:\\School Workspace\\Source Codes\\R Language\\Classifier")
df <- read.csv("train_df.csv")
str(df)
vert 'sentiment' to a factor variable (since it's categorical)
df_1000 <- df[1:1000, ]  # Select first 1000 rows
train_data <- df_1000[1:800, ]
test_data <- df_1000[801:1000, ]
# Summary of 'sentiment' count in the training data
sentiment_count <- table(as.factor(train_data$sentiment))
print(sentiment_count)
# Let's say we want to predict the 'label' column based on the 'sentiment' column
# Train a linear regression model
mod <- lm(label ~ sentiment, data = train_data)
# View summary of the linear model
summary(mod)
# Plot the linear regression model (diagnostic plots)
plot(mod)
View(sentiment_count)
View(mod)
View(df_1000)
View(train_data)
View(train_data)
View(test_data)
View(train_data)
View(mod)
View(test_data)
View(test_data)
head(train_set)
head(train_set)
dim(train_set)  # 80 tweets for training
train_set <- df[train_index, ]
train_index <- createDataPartition(df$sentiment, p = 0.8, list = FALSE)
View(train_index)
View(train_index)
